<!DOCTYPE html>
<html>

<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>pulsar</title>


<style type="text/css">
*{margin:0;padding:0;}
body {
	font:13.34px helvetica,arial,freesans,clean,sans-serif;
	color:black;
	line-height:1.4em;
	background-color: #F8F8F8;
	padding: 0.7em;
}
p {
	margin:1em 0;
	line-height:1.5em;
}
table {
	font-size:inherit;
	font:100%;
	margin:1em;
}
table th{border-bottom:1px solid #bbb;padding:.2em 1em;}
table td{border-bottom:1px solid #ddd;padding:.2em 1em;}
input[type=text],input[type=password],input[type=image],textarea{font:99% helvetica,arial,freesans,sans-serif;}
select,option{padding:0 .25em;}
optgroup{margin-top:.5em;}
pre,code{font:12px Monaco,"Courier New","DejaVu Sans Mono","Bitstream Vera Sans Mono",monospace;}
pre {
	margin:1em 0;
	font-size:12px;
	background-color:#eee;
	border:1px solid #ddd;
	padding:5px;
	line-height:1.5em;
	color:#444;
	overflow:auto;
	-webkit-box-shadow:rgba(0,0,0,0.07) 0 1px 2px inset;
	-webkit-border-radius:3px;
	-moz-border-radius:3px;border-radius:3px;
}
pre code {
	padding:0;
	font-size:12px;
	background-color:#eee;
	border:none;
}
code {
	font-size:12px;
	background-color:#f8f8ff;
	color:#444;
	padding:0 .2em;
	border:1px solid #dedede;
}
img{border:0;max-width:100%;}
abbr{border-bottom:none;}
a{color:#4183c4;text-decoration:none;}
a:hover{text-decoration:underline;}
a code,a:link code,a:visited code{color:#4183c4;}
h2,h3{margin:1em 0;}
h1,h2,h3,h4,h5,h6{border:0;}
h1{font-size:170%;border-top:4px solid #aaa;padding-top:.5em;margin-top:1.5em;}
h1:first-child{margin-top:0;padding-top:.25em;border-top:none;}
h2{font-size:150%;margin-top:1.5em;border-top:4px solid #e0e0e0;padding-top:.5em;}
h3{margin-top:1em;}
hr{border:1px solid #ddd;}
ul{margin:1em 0 1em 2em;}
ol{margin:1em 0 1em 2em;}
ul li,ol li{margin-top:.5em;margin-bottom:.5em;}
ul ul,ul ol,ol ol,ol ul{margin-top:0;margin-bottom:0;}
blockquote{margin:1em 0;border-left:5px solid #ddd;padding-left:.6em;color:#555;}
dt{font-weight:bold;margin-left:1em;}
dd{margin-left:2em;margin-bottom:1em;}
sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}
kbd {
  display: inline-block;padding: 3px 5px;font-size: 11px;line-height: 10px;color: #555;vertical-align: middle;background-color: #fcfcfc;border: solid 1px #ccc;border-bottom-color: #bbb;border-radius: 3px;box-shadow: inset 0 -1px 0 #bbb;
}
* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}
@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
}
</style>


</head>

<body>

<h2 id="toc_0">Pulsar笔记</h2>

<hr>

<p><em>written by Alex Stocks on 2018/10/16，版权所有，无授权不得转载</em></p>

<p>刚开始看 Apache Pulsar 一些资料，后面逐步补充。</p>

<h3 id="toc_1">1 Pulsar vs Kafka</h3>

<hr>

<p><img src="../pic/pulsar/pulsar_vs_kafka.webp" alt=""></p>

<p>很多人查看 Pulsar 之前可能对 Kafka 很熟悉，参照上图可见二者内部结构的区别，下面详述二者的异同以明了 Pulsar 的特点。</p>

<h4 id="toc_2">1.1 名词对应表</h4>

<hr>

<p>根据个人对<a href="https://mp.weixin.qq.com/s/CIpCLCxqpLoQVUKz6QeDJQ">参考文档1</a>的理解，整理如下<strong>Pulsar 和 Kafka名词对应列表</strong>：</p>

<table>
<thead>
<tr>
<th style="text-align: left">Pulsar</th>
<th style="text-align: left">Kafka</th>
</tr>
</thead>

<tbody>
<tr>
<td style="text-align: left">Topic</td>
<td style="text-align: left">Topic</td>
</tr>
<tr>
<td style="text-align: left">Ledger</td>
<td style="text-align: left">Partition</td>
</tr>
<tr>
<td style="text-align: left">Fragment</td>
<td style="text-align: left">Fragment/Segment</td>
</tr>
<tr>
<td style="text-align: left">Bookie</td>
<td style="text-align: left">Broker</td>
</tr>
<tr>
<td style="text-align: left">Broker</td>
<td style="text-align: left">Client SDK</td>
</tr>
<tr>
<td style="text-align: left">Ensemble Size</td>
<td style="text-align: left">Replica Number</td>
</tr>
<tr>
<td style="text-align: left">Write Quorum Size (Qw)</td>
<td style="text-align: left">metadata.broker.list</td>
</tr>
<tr>
<td style="text-align: left">Ack Quorum Size (Qa)</td>
<td style="text-align: left">request.required.acks</td>
</tr>
</tbody>
</table>

<p>Pulsar 的数据存储节点 Bookkeeper 被称为 Bookie，相当于一个 Kafka Broker。Ledger 是 Topic 的若干日志的集合，是 Pulsar 数据删除的最小单元，即 Pulsar 每次淘汰以 Ledger 为单位进行删除。Fragment 是 Bookkeeper 的概念，对应一个日志文件，每个 Ledger 有若干 Fragment 组成。 </p>

<p>Pulsar 进行数据同步时采用相关共识算法保证数据一致性。Ensemble Size 表示 Topic 要用到的物理存储节点 Bookie 个数，类似于 Kafka，其副本数目 Ensemble Size 不能超过 Bookie 个数，因为一个 Bookie 上不可能存储超过一个以上的数据副本。每次写数据时最低写入的 Bookie 个数 Qw 的上限当然是 Ensemble Size。</p>

<p>Qa 是每次写请求发送完毕后需要回复确认的 Bookie 的个数，类似于 Kafka 的 <code>request.required.acks</code>，其数值越大则需要确认写成功的时间越长，其值上限当然是 Qw。<a href="https://mp.weixin.qq.com/s/CIpCLCxqpLoQVUKz6QeDJQ">参考文档1</a> 提到 <code>为了一致性，Qa应该是：(Qw + 1) / 2 或者更大</code>，即为了确保数据安全性，Qa 下限是 <code>(Qw + 1) / 2</code>。</p>

<p><img src="../pic/pulsar/pulsar_notions.webp" alt=""></p>

<p>本小节的所有概念，以上面来自于<a href="https://mp.weixin.qq.com/s/CIpCLCxqpLoQVUKz6QeDJQ">参考文档1</a>的一幅图作为总结比较合适。</p>

<h4 id="toc_3">1.2 Kafka 的缺陷与 Pulsar 各个组件</h4>

<hr>

<p><a href="https://mp.weixin.qq.com/s/CIpCLCxqpLoQVUKz6QeDJQ">参考文档1</a> 给出了 Kafka 的一些不足：</p>

<ul>
<li>1 Kafka 每个 Partition replica 都完整的存储在kafka节点上，Partition 以及 Partition replica 由一系列的 Segment 和索引文件组成，整个架构简单快捷，但是单个节点必须有足够的磁盘空间来处理副本；</li>
<li>2 在集群扩展时必须做 Rebalance，需要 Broker 有良好的执行流程保证没有任何故障的情况下分散节点的存储压力。</li>
</ul>

<p>比较才有优劣。相比 Pulsar，Kafka 的存储模型的缺陷导致了其负载均衡能力的不足，<a href="https://jack-vanlightly.com/sketches/2018/10/2/kafka-vs-pulsar-rebalancing-sketch">参考文档3</a> 对这点很形象地以下图说明之。</p>

<p><img src="../pic/pulsar/KafkaPulsarScaling.png" alt=""> </p>

<p>Pulsar 的底层数据 以 Fragments 形式存储在多个 BookKeeper 上，当集群扩容添加 Bookies 后，Pulsar 会在新的Bookie上创建新的 Fragment，所以不需要再扩容时候像 Kafka 一样进行 Rebalance 操作，其结果就是 <code>Fragments跨多个Bookies以带状分布</code>。但是这样的结果就是同一个 Ledger 的 Fragments 分布在多个 Bookie 上，导致读取和写入会在多个 Bookies 之间跳跃。Topic的 Ledger 和 Fragment 之间映射关系等元数据存储在 Zookeeper 中，Pulsar Broker 需要实时跟踪这些关系进行读写流程。</p>

<p>Pulsar 有一个 <code>Ledger的所有权(ownership)</code> 的概念，其意义为某个 Ledger 数据所在的 Bookie。除去创建新 Ledger 的情况，当集群扩容 Pulsar 把数据写入新的 Bookie 或者 <code>当前Fragment使用Bookies发生写入错误或超时</code> 时，<code>Ledger的所有权</code> 都会发生改变。</p>

<h4 id="toc_4">1.2.1 Pulsar Producer/Consumer</h4>

<hr>

<p>Pulsar 自身支持多租户，在 zookeeper 中以 <code>/root/property/namespace/topic/ledger</code> 形式组织映射关系，<a href="https://mp.weixin.qq.com/s/4UMz2REmn7rMYHwLjGE2RQ">参考文档5</a>中的下图清晰地描述了多租户之间的组织关系：</p>

<p><img src="../pic/pulsar/pulsar_tenant.webp" alt=""></p>

<p>其中 property 是租户名称，namespace 则是业务线名称，故一个租户可以有多个 namespace，租户可以针对 namespace 设置 ACL、调整副本数目、消息过期时间等参数，至于多租户的资源控制无非是借助配额、限流、流控等手段进行。租户实质上是一种资源隔离手段，把不同业务婚部在一起，可以提高资源的利用率。</p>

<p>向 Pulsar 中写入数据者称为 Producer。Producer 向某个 Topic 写入数据时，采用不同的路由策略则一条日志消息会落入不同的 Ledger，<a href="https://mp.weixin.qq.com/s/uwmLR-1Jo_VNXRFA0yYWlg">参考文档7</a>中给出了如下四种路由策略：</p>

<ul>
<li>单个分区——生产者随机挑选一个分区，并将数据写入该分区。该策略与非分区主题提供的保证是一样的，不过如果有多个生产者向同一个主题写入数据，该策略就会很有用。</li>
<li>轮询（round robin）分区——生产者通过轮询的方式将数据平均地分布到各个分区上。比如，第一个消息写入第一个分区，第二个消息写入第二个分区，并以此类推。</li>
<li>哈希（hash）分区——每个消息会带上一个键，要写入哪个分区取决于它所带的键。这种分区方式可以保证次序。</li>
<li>自定义分区——生产者使用自定义函数生成分区对应的数值，然后根据这个数值将消息写入对应的分区。</li>
</ul>

<p>Pulsar 的 Consumer 消费消息有不同的消费模式，亦有不同的获取方式。其获取消息的方式有同步等待、异步等待和注册 MessageListener 三种方式，Consumer 可以主动向 Pulsar 拉取消息也可以等待 Pulsar 的推送，无论采用哪种方式 Consumer 接收到消息后都需要给 Pulsar 回复 acknowledgement(以下简称为ack)，回复方式有逐条回复（Individual Ack）和批量回复（Cumulative Ack）两种，关于二者的区别详见<a href="https://mp.weixin.qq.com/s/XJ3vj9xeDpdqZr-um8wBug">参考文档10</a>。类似于 Kafka 有一个内置的保存各个消费者消费 topic offset 信息的 名为 _<em>consumer</em>offsets 的 topic，Pulsar 也有专门的 ledger 记录 Consumer 的 ack 并移动其消息消费游标(Cursor)。Pulsar 和 Consumer 之间消费消息的方式是一种推拉相结合的方式，详细内容见<a href="http://www.cnblogs.com/hzmark/p/pulsar-consumer.html">参考文档6</a> 。</p>

<p><img src="../pic/pulsar/pulsar_sub.webp" alt=""></p>

<p>Pulsar 不同 Consumer 可以针对同一个 Topic 指定不同的消费模式。如上图所示，消费模式主要有独享（Exclusive）、共享（Shared）或故障转移（Failover）三种。Exclusive 可以认为是 Failover 的一个特例，两种消费方式都可以保证消息有序的传递给 Consumer，并方便 Consumer 以批量方式提交 ack，区别就是 Exclusive 无法保证消费者高可用。</p>

<p><img src="../pic/pulsar/pulsar_consumer_group.webp" alt=""></p>

<p>如上图，Pulsar Shared 消费方式则类似于 kafka 的 Consumer Group 的消费方式，Pulsar 以 Round-Robin 的方式把消息分发给一组消费群内的每个 Consumer，缺点是无法保证消息的有序性，且每个 Consumer 须对每个消息都回复 ack。</p>

<h4 id="toc_5">1.2.2 Pulsar Broker</h4>

<hr>

<p>Pulsar 的 metadata 存储在 zookeeper 上，而消息数据存储在 Bookkeeper 上。Broker 虽然需要这些 metadata，但是其自身并不持久化存储这些数据，所以可以认为是无状态的。不像 Kafka 是在 Partition 级别拥有一个 leader Broker，Pulsar 是在 Topic 级别拥有一个 leader Broker，称之为拥有 Topic 的所有权，针对该 Topic 所有的 R/W 都经过改 Broker 完成。</p>

<p>Pulsar Broker 可以认为是一种 Proxy，它对 client 屏蔽了服务端读写流程的复杂性，是保证数据一致性与数据负载均衡的重要角色，所以 Pulsar 可以认为是一种基于 Proxy 的分布式系统。与之形成对比的 kafka 可以认为是一种基于 SmartClient 的系统，所以 Kafka 服务端自身的数据一致性流程还需要 Client SDK 与之配合完成。</p>

<p><a href="https://mp.weixin.qq.com/s/0dkgA8swNPkpcY5H6CU62w">参考文档2</a>如下一幅图可以帮助理解 Pulsar Broker 的 proxy 角色。</p>

<p><img src="../pic/pulsar/pulsar_proxy.webp" alt=""> </p>

<p>上图中的 Writer Proxy 和 Read Proxy 两个逻辑角色的功能由 Pulsar Broker 这一物理模块完成。</p>

<p>Kafka 的所有 Broker 会选出一个 Leader，作为 Broker Leader 决定 Broker 宕机判断、集群扩容、创建删除 Topic、Topic Replica分布、Topic Partition 的 Leader 的选举。Pulsar 的所有 Broker 也会借助 zookeeper 加锁的方式选举一个 Leader【或者称为 Master 更合适，以区分于 Topic 的 Leader】，对 Broker 宕机判断（Failover）、根据 Bookie 集群负载Topic Ledger 所有权【即 Ledger 所在的 Bookie】等任务，具体代码细节可参见 Pulsar LoadManager 相关流程。</p>

<h3 id="toc_6">2 Pulsar 读写过程</h3>

<hr>

<p>在第一章节详细介绍了 Pulsar 的相关概念。对 Kafka 读写流程比较熟悉的人应该会对 Pulsar 的读写流程了然于胸，本节借用<a href="https://mp.weixin.qq.com/s/CIpCLCxqpLoQVUKz6QeDJQ">参考文档1</a>的两幅图对读写流程简略叙述后，重点详述 Pulsar 的 fencing 机制，其是保证 Pulsar 数据 CAP 特性中的 Consistency 一项的关键。</p>

<h4 id="toc_7">2.1 写流程</h4>

<hr>

<p>Pulsar 的写流程如下图：</p>

<p><img src="../pic/pulsar/pulsar_write.webp" alt=""> </p>

<p>Pulsar Broker 接收到 client 的请求后，依据 Topic 所使用的 Ensemble 集合以及相关参数，把数据写入 Qw 个 Bookie，收到 Qa 个 Bookie 的回应后，可以认为写成功。<font color=blue>至于 Ensemble 的选择，则由 Pulsar Broker Leader 通过如同机房同机柜以及负载等相应的策略在创建 Topic 的时候从 Bookie 集合中选择。</font></p>

<p><img src="../pic/pulsar/pulsar_bookie_striple.webp" alt=""></p>

<p>如上图，Bookie Ensemble 数目是 5，Qw 为 3，Broker 可以用这种条带化方式把数据 Entry x 写入各个 Bookie。<font color=blue>每个 Bookie 有一个 Auditor 线程跟踪自身负责的 Entry 集合是否有数据副本缺失【如当 Bookie 1 接收到 Entry 6 时，Auditor 会检测 Entry 5 是否已经收到】，当其发现数据有缺失的时候会从副本集中其他副本复制数据。</font></p>

<p>如果写流程中有 Bookie 返回错误或者超时没有返回，<font color=red>则 Broker 会用新的 Bookie 替换之</font>，并把数据写入其中的 Ledger/Fragment上。通过这个称之为 <code>Ensemble Change</code> 的方法能够保证 Pulsar 肯定能够写成功，而不是由于某个节点故障导致写流程阻塞住进而影响后面 Entry 的写流程。</p>

<p><img src="../pic/pulsar/pulsar_striple.png" alt=""></p>

<p>如果写流程中 Pulsar Broker 发生崩溃，Failover 流程【#2.3 fencing#小节会详述之】完成后，新的 Pulsar Broker 会关闭上个 Broker 写的 Ledger，而后创建新的 Ledger 进行写入。</p>

<p>Pulsar Bookie 是一种日志型存储引擎，每条 Log 称之为 Entry，每个 Log 的 ID 称谓 Entry ID。Entry ID 从0开始有序递增，<Ledger ID, Entry ID> 即唯一的确定了一个 Entry 的坐标。</p>

<p>Pulsar 可以缓存写流程中的部分尾部数据用于加快 client 的读取数据流程，并记下最后一条写成功的消息的 ID（Last Add Confirmed ID，称之为 LAC），可以用来检验读请求的合法性。所有 Entry ID 小于 LAC 的即可确认是 commited index，都可以被安全读出。</p>

<p>与 LAC 相应的，Pulsar 还有一个称谓 LAP 的概念，其全称为 Last-Add-Pushed，即已经发送给 Bookie 但是尚未收到 Ack 的日志条目，整个机制类似于 TCP 发送端的滑动窗口。</p>

<h4 id="toc_8">2.2 读流程</h4>

<hr>

<p>Pulsar Consumer 读取消息的不需要关心数据数据存储所在的介质，因为 Pulsar 很好的使用了缓存功能以提高读取速度，并利用分级方式降低存储成本。</p>

<p><img src="../pic/pulsar/pulsar_cache.png" alt=""></p>

<p>如上图所示，除了 Broker 自身的 Cache，这个层级存储方式使用了 AWS S3 以及其他的一些存储介质，但对整体集群性能影响并不大。 </p>

<p>Pulsar 的读流程如下图：</p>

<p><img src="../pic/pulsar/pulsar_read.webp" alt=""> </p>

<p>Kafka 的 Consumer 会从 Partition 对应的 leader Broker 上读取数据，Pulsar 的 client 是从 Topic owner 对应的 Broker 读取数据。如果该 Broker 有缓存，则直接返回相应数据，否则就从任一个 Bookie 读取数据并返回给 client。</p>

<p>一个新的 Pulsar Broker 发起读取请求之前，需要知道 Pulsar 集群的 LAC，Broker 会向所有 Bookie 发送获取 LAC 请求，得到大多数回复后即可计算出一个安全的 LAC 值，这个流程就是采用了 Quorum Read 的方式。 </p>

<p>Pulsar Broker 获取可靠的 LAC 之后，其读取可以从任一 Bookie 开始，如果在限定时间内没有响应则给第二个 Bookie 发送读取请求，然后同时等待这两个 Bookie，谁先响应就意味着读取成功，这个流程称之为 Speculative Read。</p>

<h4 id="toc_9">2.3 fencing</h4>

<hr>

<p>上面提到 Pulsar Broker 本质上是一个 Proxy，其区别就是自身是无状态的：不存储任何状态数据。Broker 决定了数据如何分片，保证数据一致性，具有常见分布式系统 leader-follower 架构中 leader 的部分职权：当一个 Topic owner 所在的 Broker 宕机时，要选举出一个新的 Broker 作为 Topic owner。同 Raft leader 选举一样，选举过程中不处理数据读写请求。</p>

<p><a href="https://mp.weixin.qq.com/s/CIpCLCxqpLoQVUKz6QeDJQ">参考文档1</a>描述了整个选举流程如下：</p>

<ul>
<li>1 Topic X 的当前拥有者(B1)不可用(通过Zookeeper);</li>
<li>2 其他Broker(B2)将Topic X 的当前Ledger状态从OPEN修改为IN_RECOVERY;</li>
<li>3 B2向Ledger的当前Fragment的Bookies发送fence信息并等待(Qw-Qa) + 1个Bookies响应。收到此响应数后Ledger将变成fenced。如果旧的Broker仍然处于活跃状态则无法再进行写入，因为无法获得Qa确认(由于fencing导致异常响应);</li>
<li>4 B2然后从Fragment的Bookies获得他们最后确认的条目是什么。它需要最新条目的ID，然后从该点开始向前读。它确保从哪一点开始的所有条数(可能以前未向Pulsar Broker承认)都会被复制到Qw Bookies。一旦B2无法读取并复制任何条目，Ledger将完全恢复;</li>
<li>5 B2将Ledger的状态更改为CLOSED;</li>
<li>6 B2现在可以创建新的Ledger并接受写入请求。</li>
</ul>

<p>整个流程 Pulsar 称之为 fencing。如果对 Codis 数据迁移流程了解的人应该会觉得这个流程与 Codis Migration 操作流程甚是相似，<a href="https://www.csdn.net/article/2015-02-02/2823796-spark-codis-crazyjvm-goroutine/2">参考文档4</a>给出了 Codis Migration 流程如下：</p>

<p><img src="../pic/pulsar/codis_migration.jpg" alt=""> </p>

<p>Codis 也是一种基于 Proxy 的分布式存储系统，架构实质与 Pulsar 无多大差别，所以二者流程类似也在清理之中。Fencing 本质就是一个分布式加锁协议，与 2PC 协议类似，本质上与多 CPU core 之间数据一致性协议 MESI 协议也无差。</p>

<h4 id="toc_10">2.4 Bookie 数据读写流程</h4>

<hr>

<p>Pulsar 的数据最终是靠 Bookkeeper(Bookie) 落地的，各个 Pulsar Bookie 之间是平等的，kafka 的存储节点在 Partition 层次上有主从之分。单个 Broker 数据写流程如下：</p>

<ul>
<li><p>1 将写请求记入 WAL【类似于数据库的 Journal 文件】；</p>

<blockquote>
<p>一般工程实践上建议把 WAL 和数据存储文件分别存储到两种存储盘上，如把 WAL 存入一个 SSD 盘，而数据文件存入另一个 SSD 或者 SATA 盘。 </p>
</blockquote></li>
<li><p>2 将数据写入内存缓存中；</p></li>
<li><p>3 写缓存写满后，进行数据排序并进行 Flush 操作，排序时将同一个 Ledger 的数据聚合后以时间先后进行排序，以便数据读取时快速顺序读取；</p></li>
<li><p>4 将 &lt;(LedgerID, EntryID), EntryLogID&gt; 写入 RocksDB。</p>

<blockquote>
<p>LedgerID 相当于 kafka 的 ParitionID，EntryID 即是 Log Message 的逻辑 ID，EntryLogId 就是 Log消息在 Pulsar Fragment文件的物理 Offset。</p>

<p>这里把这个映射关系存储 RocksDB 只是为了加快写入速度，其自身并不是 Pulsar Bookie 的关键组件。</p>
</blockquote></li>
</ul>

<p><img src="../pic/pulsar/pulsar_read_write_isolation.png" alt="">   </p>

<p>结合上图，可以对上述流程有更清晰的认识。若与对 Elasticsearch 的写入刷盘流程进行比较，会发现二者流程比较相似。其实其与 RocksDB 写流程也有相似之处，只不过 RocksDB 需要维持数据的状态机，而日志型存储系统 Pulsar 不需要对数据进行计算或者整理，故其还有 Bookkeeper 没有的基于 LSM 的对数据进行 compaction 的整理流程，或者也可以说 Pulsar 把对数据的重新整理交个 Consumer 自己进行处理，自身只负责按照提交先后顺序维持 Entry 的有序存储即可。</p>

<p>Bookie 的整个写入流程除了自身把内存缓存数据批量刷盘一步外，整个流程几乎不需要跟磁盘进行IO，所以速度也是极快。</p>

<p>其读取流程如下：</p>

<ul>
<li>1 从写缓存读取数据【因为写缓存有最新的数据】；</li>
<li>2 如果写缓存不命中，则从读缓存读取数据；</li>
<li>3 如果读缓存不命中，则根据 RocksDB 存储的映射关系查找消息对应的物理存储位置，然后从磁盘上读取数据；</li>
<li>4 把从磁盘读取的数据回填到读缓存中；</li>
<li>5 把数据返回给 Broker。</li>
</ul>

<p>整个读写流程借用<a href="https://mp.weixin.qq.com/s/CIpCLCxqpLoQVUKz6QeDJQ">参考文档1</a>一图描述如下：</p>

<p><img src="../pic/pulsar/pulsar_data_storage.webp" alt=""></p>

<p>如果 Bookie 意外崩溃，则其重启后需要进行数据恢复，执行这个任务的流程称之为 AutoRecoveryMain。AutoRecoveryMain 任务是由若干个 worker 线程构成的线程池执行的，每个 worker 线程从由自己负责的 zookeeper path 上找到要恢复数据的 Ledger 进行数据复制。</p>

<p><img src="../pic/pulsar/pulsar_striple.png" alt=""></p>

<p>如果集群发生扩容，则由 Auditor 线程负责 Segment 数据的迁移复制。</p>

<h2 id="toc_11">参考文档</h2>

<blockquote>
<p>1 <a href="https://mp.weixin.qq.com/s/CIpCLCxqpLoQVUKz6QeDJQ">理解Apache Pulsar工作原理</a><br>
2 <a href="https://mp.weixin.qq.com/s/0dkgA8swNPkpcY5H6CU62w">Twitter高性能分布式日志系统架构解析</a><br>
3 <a href="https://jack-vanlightly.com/sketches/2018/10/2/kafka-vs-pulsar-rebalancing-sketch">Kafka vs Pulsar - Rebalancing (Sketch)</a><br>
4 <a href="https://www.csdn.net/article/2015-02-02/2823796-spark-codis-crazyjvm-goroutine/2">
Spark生态系统解析及基于Redis的开源分布式服务Codis</a><br>
5 <a href="https://mp.weixin.qq.com/s/4UMz2REmn7rMYHwLjGE2RQ">Apache Pulsar的多租户</a><br>
6 <a href="http://www.cnblogs.com/hzmark/p/pulsar-consumer.html">Pulsar Consumer实现介绍</a><br>
7 <a href="https://mp.weixin.qq.com/s/uwmLR-1Jo_VNXRFA0yYWlg">简介Apache Pulsar-下一代分布式消息系统</a><br>
8 <a href="https://mp.weixin.qq.com/s/qWgLsDYYL2G1V6O2XHVxbw">Apache Pulsar中的多地互备，第1篇：概念和功能</a><br>
9 <a href="https://mp.weixin.qq.com/s/3cfs7pXQDmMWGJRB8criRg">Apache Pulsar中的多地互备，第2篇：模式和实践</a><br>
10 <a href="https://mp.weixin.qq.com/s/XJ3vj9xeDpdqZr-um8wBug">Pulsar VS. Kafka（1）: 统一的消息消费模型（Queue + Stream）</a><br>
11 <a href="https://mp.weixin.qq.com/s/zcole6BuAzP9durwAbrUpg">Pulsar VS. Kafka（2）: 以Segment为中心的架构</a>  </p>
</blockquote>

<h2 id="toc_12">扒粪者-于雨氏</h2>

<blockquote>
<p>2018/10/18，于雨氏，初作此文于西二旗。</p>

<p>2018/10/20，于雨氏，于丰台完成 # 2 Pulsar 读写过程 #。</p>
</blockquote>


<!-- baidu statistic start -->
<script>
var _hmt = _hmt || [];
(function() {
	  var hm = document.createElement("script");
	    hm.src = "https://hm.baidu.com/hm.js?170a8df8802fbc47c7acc272d270979c";
		  var s = document.getElementsByTagName("script")[0];
		    s.parentNode.insertBefore(hm, s);
})();
</script>
<!-- baidu statistic end -->

<!-- Gitalk start -->
<link rel="stylesheet" href="https://unpkg.com/gitalk@latest/dist/gitalk.css">
<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script>
<div id="gitalk-container"></div>
<script type="text/javascript">
var gitalk = new Gitalk({
	clientID: '6211d8b94a8106bed6b0',
	clientSecret: 'bf77ca26c237eabbd45169e01bf03a5e96a1b26f',
	repo: 'alexstocks.github.io',
	owner: 'AlexStocks',
	admin: ['AlexStocks'],
	id: window.location.pathname,
	distractionFreeMode: true
});
gitalk.render('gitalk-container');
</script>
<!-- Gitalk end -->




</body>

</html>
